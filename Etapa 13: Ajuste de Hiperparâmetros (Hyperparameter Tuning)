*Ajuste de hiperparâmetros para o Random Forest

#Importar as bibliotecas necessárias:

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

*Aqui estamos importando o RandomForestClassifier para construir o modelo de Random Forest e as classes GridSearchCV e RandomizedSearchCV para realizar a busca de hiperparâmetros.

#Definir o espaço de busca de hiperparâmetros para o modelo de Random Forest:
param_grid = {
    'n_estimators': [50, 100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2']
}

# Instanciar o modelo e configurar o Grid Search:
modelo_random_forest = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(estimator=modelo_random_forest,
                           param_grid=param_grid,
                           cv=3,
                           n_jobs=-1,
                           verbose=2)

#Treinar o Grid Search:
grid_search.fit(X_train, y_train)

#Obter os melhores hiperparâmetros:
melhores_params_random_forest = grid_search.best_params_
print("Melhores hiperparâmetros para Random Forest:", melhores_params_random_forest)

#Instanciar e treinar o modelo com os melhores hiperparâmetros:
random_forest_melhorado = RandomForestClassifier(max_depth=10, max_features='sqrt', min_samples_leaf=2, min_samples_split=10, n_estimators=100)
random_forest_melhorado.fit(X_train, y_train)

#Previsão no conjunto de validação:
previsao_random_forest_melhorado = random_forest_melhorado.predict(X_val)

#Avaliar o desempenho do modelo:
print(f"Acurácia: {accuracy_score(y_val, previsao_random_forest_melhorado)}")
print(classification_report(y_val, previsao_random_forest_melhorado))

#Exibir a matriz de confusão:
matriz_random_forest_melhorado = confusion_matrix(y_val, previsao_random_forest_melhorado)
sns.heatmap(matriz_random_forest_melhorado, annot=True, fmt="d", cmap="Blues")
plt.title("Matriz de Confusão - Random Forest Melhorado")
plt.xlabel("Previsto")
plt.ylabel("Real")
plt.show()

*Ajuste de hiperparâmetros para XGBoost

#Importar as bibliotecas necessárias:
import xgboost as xgb
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix


#Definir o espaço de busca de hiperparâmetros:
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}


#Instanciar e configurar o Grid Search:
modelo_xgb = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')
grid_search = GridSearchCV(estimator=modelo_xgb, param_grid=param_grid, scoring='accuracy', cv=6, n_jobs=-1, verbose=1)


#Treinar o Grid Search:
grid_search.fit(X_train, y_train)

#Verificar os melhores parâmetros:
print("Melhores Hiperparâmetros:", grid_search.best_params_)

#Previsão e Avaliação:
modelo_xgb_melhorado = grid_search.best_estimator_
previsao_xgb_melhorado = modelo_xgb_melhorado.predict(X_val)
print("Acurácia:", accuracy_score(y_val, previsao_xgb_melhorado))
print("Relatório de Classificação:\n", classification_report(y_val, previsao_xgb_melhorado))


#Matriz de Confusão para XGBoost:
matriz_xgb_melhorado = confusion_matrix(y_val, previsao_xgb_melhorado)
sns.heatmap(matriz_xgb_melhorado, annot=True, fmt="d", cmap="Blues")
plt.title("Matriz de Confusão - XGB Melhorado")
plt.xlabel("Previsto")
plt.ylabel("Real")
plt.show()
